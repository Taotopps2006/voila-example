{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# produce vector inline graphics\n",
    "# from IPython.display import set_matplotlib_formats, display, Markdown, HTML\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = [10, 4]\n",
    "# display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data for [Voil√†](https://github.com/voila-dashboards/voila) dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we turned our exploratory notebook directly into a Voila app. When we started that app, it needed to run every cell in the notebook to produce results. \n",
    "\n",
    "This is inefficient. Our end-user shouldn't have to wait for this code to run every time they want to see the dashboard. This becomes especially relevant as we start doing more machine learning, or really any computations that take a considerable time to run. \n",
    "\n",
    "In this notebook, we'll reproduce the pre-processing steps needed for the dashboard. We will then save new data and export our ML model.\n",
    "\n",
    "We need to run this notebook before we run the new, faster Voila app. In a production setting, we could separate these two *services* into separate applications, e.g. two separate Heroku apps connected to the same database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We'll be using an [example dataset](https://raw.githubusercontent.com/shubham13p/Ad-Click-Prediction/master/advertising.csv) found on GitHub. We'll use Pandas to load in this data and display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/shubham13p/Ad-Click-Prediction/master/advertising.csv')\n",
    "df['Click_labeled'] = df['Clicked on Ad'].apply(lambda x: \"Click\" if x == 1 else \"No Click\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib / Altair plots\n",
    "\n",
    "If we wanted to, we could generate and export the our plots as standalone  files ahead of time. If we took that approach, we could actually embed them in *static* HTML, and we might not even need Voila. This is even true for the interactive plots!\n",
    "\n",
    "We won't go into too much detail about this, but Altair has the benefit of creating charts that run completely on Javascript. As such, they don't need any real backend to run. We could have rich, interactive charts even on something like GitHub Pages, or any static HTML server.\n",
    "\n",
    "So, again, **why use Voila?**\n",
    "\n",
    "**Pros:**\n",
    "* Integrates directly with Jupyter workflow\n",
    "* Less overhead - we don't need to build a separate app or any other infrastructure\n",
    "\n",
    "**Cons:**\n",
    "* Slower to run\n",
    "* Less flexibility than other frameworks\n",
    "\n",
    "So the main use-case for Voila is in **protyping** a report, app, or dashboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "Here, we'll handle the ML part of the app and add those features to the DataFrame. If we wanted to, we could save the topic model and load it in our Voila app, but we don't really need to. \n",
    "\n",
    "**Q: When would we want to include the model in the Voila app?** A: If we needed to generate predictions interactively. We're just using the model for descriptive analysis, rather than predictive, so we just need to save the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=0.9, min_df=10, stop_words='english')\n",
    "\n",
    "# Create matrix of TFIDF features\n",
    "doc_term_matrix = tfidf_vect.fit_transform(df['Ad Topic Line'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NMF model\n",
    "nmf = NMF(n_components=3, random_state=42)\n",
    "nmf.fit(doc_term_matrix )\n",
    "\n",
    "# Create matrix of NMF outputs\n",
    "topic_values = nmf.transform(doc_term_matrix)\n",
    "\n",
    "# Assign the most relevant topic to each row in the DataFrame\n",
    "df['Topic'] = topic_values.argmax(axis=1) + 1\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_components = nmf.components_\n",
    "\n",
    "np.save('data/nmf-components.npy', nmf_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "with open('data/feature-names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
